{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test['text'].tolist()\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMDDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], truncation=True, max_length=256, padding='max_length', return_tensors='pt')\n",
    "        return {key: val.squeeze() for key, val in encoding.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['generated', 'human']\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_TextClassifier_Model():\n",
    "    def __init__(self, pretrained_transformer_name='../input/save-model/save_model/'):\n",
    "        max_samples = {'test': 100000}\n",
    "        test_texts = test_text[:max_samples['test']]\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_transformer_name)\n",
    "        self.test_dataset = LLMDDatasetTest(test_texts, self.tokenizer)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(pretrained_transformer_name,\n",
    "                                                                        num_labels=len(LABELS),\n",
    "                                                                        id2label=id2label,\n",
    "                                                                        label2id=label2id)\n",
    "        \n",
    "    def inference(self):\n",
    "        loader = DataLoader(self.test_dataset, batch_size=16, shuffle=False)\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                outputs = self.model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "                logits = outputs.logits\n",
    "                probs = np.exp(logits.numpy()) / np.sum(np.exp(logits.numpy()), axis=1, keepdims=True)\n",
    "                predictions.extend(probs[:,0].tolist())\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_trainer = My_TextClassifier_Model(pretrained_transformer_name='../input/save-model/save_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classification_trainer.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results[\"id\"] = test[\"id\"]\n",
    "results[\"generated\"] = preds\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e22863",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
